{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potentiel des méthodes de deep learning pour cartographier l’occupation du sol de La Réunion à partir d’images de télédétection\n",
    "\n",
    "Les dfférentes section de ce NoteBook permettent d'implémenter un réseau de neurones. <br>\n",
    "Ainsi, après avoir construit le dataset à l'aide d'une image pléaide + polygones de verités terrain il s'agit de préparer cette base de donnée.<br>\n",
    "Ensuite, il faut définir les métriques utilisées pour evaluer le réseau ainsi que les paramètres du réseau que l'on va faire varier. <br>\n",
    "Les métriques que l'on fait varier dans ce notebook sont : <br>\n",
    "- Matrice de confusion <br>\n",
    "- Accuracy <br>\n",
    "- Loss <br>\n",
    "\n",
    "### Important \n",
    "   Tous les modules sont à télecharger en temps qu'administrateur.. <br>\n",
    "   Imports avec quelques problèmes de version : gdal, tf <br>\n",
    "   Le modèle cnn est fait sur Keras, il est important de rester en Keras pour utiliser le code (et pas \"tf.keras\")\n",
    "    \n",
    "### Rôle de chaque fichier dans le dossier: \n",
    "\n",
    "**Dataset** : <br>\n",
    "    -Image GéoTiff Pléaide <br>\n",
    "    - Vérité terrain.shp <br>\n",
    "    -Dossier \"Dataset_xx\" avec xx la taille de l'imagette <br>\n",
    "\n",
    "**Fichiers de code** : <br>\n",
    "    - Base de donées : Le fichier \"Creation_Dataset\" <br>\n",
    "    - Main_metrics : ce fichier \n",
    "    - Classification : Inférence du cnn. \n",
    "    \n",
    "    \n",
    "Remarques pour compiler le code : <br>\n",
    "-si le training ne marche pas, fermer tous les processus pyhton et recommencer <br>\n",
    "-si le résultat n'est pas celui esperé --> restart Kenerl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sommaire\n",
    "\n",
    "* [Variables](#chapter0) \n",
    "* [Fonctions](#chapter1) \n",
    "* [Dataset](#chapter2)\n",
    "    * [Affichage](#section_1)\n",
    "    * [Résumé des diccionaires et listes ](#section_1_2)\n",
    "    * [Gestion de la base de donée](#section_1_3)\n",
    "* [Implémentation du CNN](#chapter2)\n",
    "    * [Modèle](#section_2_2)\n",
    "    * [Training](#section_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables <a class=\"anchor\" id=\"chapter0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Chemin de la vérité terrain : fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = 'Dataset_50x50_Niveau2_v9.csv' \n",
    "nb_class= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documentation : Parralèlisme avec Tensorflow / Comet** <br>\n",
    "https://github.com/comet-ml/comet-examples/blob/master/tensorflow-1/comet-tf1-distributed-mirrored-strategy.py <br>\n",
    "\n",
    "Comet permet de visualiser les \"expériences\" lors de la recherche de meilleures combinaisons pour les hyperparamètres. <br>\n",
    "L'interface permet également de visualiser l'évolution des métriques pour un modèle en particulier. <br>\n",
    "Clé API : Ult9nmi0NXwIYT8yNAlg17jxP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Comet API key is valid\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Optimizer\n",
    "comet_ml.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numpy\n",
    "import h5py\n",
    "import scipy\n",
    "import io\n",
    "from datetime import datetime \n",
    "\n",
    "#import pandas as pd\n",
    "from pandas import read_csv\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from keras import backend\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework import ops\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "import csv \n",
    "\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "from numpy import asarray\n",
    "#from cnn_utils import *\n",
    "#from pyrsgis import raster\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from plot_model import plot_model\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#Plusieurs fichiers pour ne pas etouffer le code \n",
    "import import_ipynb\n",
    "#import functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Beaucoup d'imports.... mais ca facilite la vie !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/benlamlih/remote-sensing-classif/f1505feb0efa415a8c89205c8be4d4c0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = comet_ml.Experiment(\n",
    "    project_name=\"DeepLearning_MOS\", \n",
    ")\n",
    "experiment.add_tag(\"niveau2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f1505feb0efa415a8c89205c8be4d4c0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.get_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Lors de la recherche d'hyperparamètres, on chosiit l'algortihme Bayésien et on définit les paramètres à faire varier ainsi que leurs plages de valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need to specify the algorithm and hyperparameters to use:\n",
    "config = {\n",
    "    # We pick the Bayes algorithm:\n",
    "    \"algorithm\": \"bayes\",\n",
    "\n",
    "    # Declare your hyperparameters in the Vizier-inspired format:\n",
    "    \"parameters\": {\n",
    "        \"dropout\": {\"type\": \"float\", \"min\": 0, \"max\": 1},\n",
    "        \"nunits\" : {\"type\": \"integer\", \"min\": 200, \"max\": 1000 }\n",
    "    },\n",
    "\n",
    "    # Declare what we will be optimizing, and how:\n",
    "    \"spec\": {\n",
    "      \"metric\": \"test_acc\",\n",
    "      \"objective\": \"maximize\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: COMET_OPTIMIZER_ID=c3f0a884cba74c828ed4bed09955b47b\n",
      "COMET INFO: Using optimizer config: {'algorithm': 'bayes', 'configSpaceSize': 'infinite', 'endTime': None, 'id': 'c3f0a884cba74c828ed4bed09955b47b', 'lastUpdateTime': None, 'maxCombo': 0, 'name': 'c3f0a884cba74c828ed4bed09955b47b', 'parameters': {'dropout': {'max': 1, 'min': 0, 'scalingType': 'uniform', 'type': 'float'}}, 'predictor': None, 'spec': {'gridSize': 10, 'maxCombo': 0, 'metric': 'test_acc', 'minSampleSize': 100, 'objective': 'maximize', 'retryAssignLimit': 0, 'retryLimit': 1000}, 'startTime': 17273548909, 'state': {'mode': None, 'seed': None, 'sequence': [], 'sequence_i': 0, 'sequence_pid': None, 'sequence_retry': 0, 'sequence_retry_count': 0}, 'status': 'running', 'suggestion_count': 0, 'trials': 1, 'version': '2.0.1'}\n"
     ]
    }
   ],
   "source": [
    "opt = Optimizer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "#### Utilitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512974\n",
      "Stored 'lignes' (int)\n"
     ]
    }
   ],
   "source": [
    "#On commence par le commencement : Importer la vérité terrain ici de la création de la base de donnée \n",
    "#with open(datafile_path, 'r') as f:\n",
    "    #mapping_csv  = csv.reader(f)\n",
    "mapping_csv = read_csv(datafile_path)\n",
    "\n",
    "#Fonction utile pour la suite \n",
    "def getElem(file, i, j):\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for line in reader:\n",
    "            if reader.line_num - 1 == i:\n",
    "                return line[j]\n",
    "            \n",
    "def csvcount(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        i = 0\n",
    "        for ligne in f:\n",
    "            i += 1\n",
    "    return i\n",
    "lignes= csvcount(datafile_path)\n",
    "print(lignes)\n",
    "%store lignes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage de quelques images du dataset <a class=\"anchor\" id=\"section1\"></a>\n",
    "\n",
    ">Dé-commenter les prints pour voir le résultat des fonctions  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot the first 9 images in the  dataset (au choix)\n",
    "#for i in [2,4,6,8,10,12,14]:\n",
    "# define subplot\n",
    "i=2\n",
    "pyplot.subplot(330 + 1+i)\n",
    "    # define filename\n",
    "filename = getElem(datafile_path, i, 0)\n",
    "print(getElem(datafile_path, i, 2))\n",
    "    # load image pixels\n",
    "rasterArray = gdal_array.LoadFile(str(filename))\n",
    "rasterArray = rasterArray.transpose(1, 2, 0)\n",
    "print(rasterArray)\n",
    "image = imread('Dataset_50x50_Niveau2_v9/1/4230230.0.tif')\n",
    "    # plot raw pixel data\n",
    "pyplot.imshow(image)\n",
    "    # show the figure\n",
    "pyplot.show()\n",
    "rasterArray = gdal_array.LoadFile(str(filename))\n",
    "rasterArray = rasterArray.transpose(1, 2, 0)\n",
    "print(rasterArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Création de différents dictionnaires à partir du fichier cvs afin de créer une base de donnée homogène quelque soit le cnn choisie. <br>\n",
    ">La sortie du cnn sera un vecteur ligne de zéros avec un '1' à la position de la classe associée issue de la vérité terrain <br>\n",
    "\n",
    "### Résumé des diccionaires et listes <a class=\"anchor\" id=\"section_1_2\"></a>\n",
    "<ul>\n",
    "<li> Mapping: lier le label et le numero de la classe </li>\n",
    "<li> file_mapping : lier le nom du fichier et sa classe </li>\n",
    "<li> Target : vecteur sortie </li>\n",
    "<li> Labels : noms des classes </li>\n",
    "<li> Tags : numéro des classes - niveau 3 (en int) </li>\n",
    "<li> Tags1 : numéro des classes - niveau 3 (en string) </li>\n",
    "\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mapping = {\n",
    "    \"Canne a sucre\" : 0,\n",
    "    #\"Friches\" : 2,\n",
    "    \"Prairie paturees\" : 1, \n",
    "    \"Prairie fauchees\" : 2,\n",
    "    \"Autres cultures maraicheres\" : 3,\n",
    "    \"Pomme de terre\" : 4,\n",
    "    \"Ananas\" : 5,\n",
    "    \"Culture sous serre ou ombrage\" : 6,\n",
    "    \"Verger agrume\" : 7,\n",
    "    \"Verger de letchi et ou longani\" : 8,\n",
    "    \"Verger de manguier\" : 9,\n",
    "    \"Plantation de cocotier\" : 10,\n",
    "    \"Plantation de bananier\" : 11,\n",
    "    \"Forets et fourres de montagne\" : 12,\n",
    "    \"Autre vegetation arboree\" : 13,\n",
    "    \"Plantation forestiere\": 14,\n",
    "    \"Vegetation altimontaine\": 15,\n",
    "    \"Lande de rempart\" : 16,\n",
    "    \"Savane herbacee de basse altitude\" : 17,\n",
    "    \"Vegetation arbustive\" : 18, \n",
    "    \"Massif de vigne maronne\" :19, \n",
    "    \"Vegetation naturelle sur coulee de lave\": 20,\n",
    "    \"Rochers et sol sans ou avec peu de vegetation\" : 21,\n",
    "    \"Ombre due au relief\":22,\n",
    "    \"Marais\":23,\n",
    "    \"Surface en eau\" : 24,\n",
    "    \"Surface batie\" : 25,\n",
    "    \"Panneau photovoltaique\" : 26,\n",
    "    \"Route et parking\" : 27,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation de dicctionaires pour faciliter la lecture de datasets \n",
    "#Create a diccionary to link labels and class (fait manuellement)\n",
    "mapping = {\n",
    "    \"Canne a sucre\" : 0,\n",
    "    \"Paturage et fourrage\" :1,\n",
    "    \"Maraichage\": 2,\n",
    "    \"Arboriculture\": 3,\n",
    "    \"Espace boise\": 4,\n",
    "    \"Lande et savane\":5,\n",
    "    \"Rocher et sol nu naturel\":6,\n",
    "    \"Ombre due au relief\":7,\n",
    "    \"Eau\":8,\n",
    "    \"Espace artificialise\":9,\n",
    "    \"Culture sous serre ou ombrage\":10,\n",
    "}\n",
    "\n",
    "#Create a set of labels \n",
    "#boucle sur le [0] du diccionaire \n",
    "labels = []\n",
    "for k,v in mapping.items():\n",
    "    labels.append(k)\n",
    "    \n",
    "#Create a set of tags (class) \n",
    "#boucle sur le [0] du diccionaire \n",
    "tags = []\n",
    "for k,v in mapping.items():\n",
    "    tags.append(int(v))\n",
    "\n",
    "#listes spéciales pour la matrice de confusion \n",
    "tags1 = []\n",
    "for k,v in mapping.items():\n",
    "    tags1.append(v)\n",
    "    \n",
    "    \n",
    "# create a mapping of filename to tags \n",
    "def create_file_mapping(mapping_csv):\n",
    "    mapping = dict()\n",
    "    for i in range(len(mapping_csv)):\n",
    "        name, tags = mapping_csv['Image FileName'][i], mapping_csv[' Class'][i]\n",
    "        mapping[name] = tags\n",
    "    return mapping\n",
    "\n",
    "\n",
    "#Transform each class into a vector of loads of 0 and a single 1 \n",
    "def one_hot_encode(tags, mapping):\n",
    "    # create empty vector\n",
    "    # mark 1 for each tag in the vector\n",
    "    encoding = zeros(nb_class, dtype='int8')\n",
    "    #Modification pour la classe friche qui a le code 200 en 2020 et qui est converti en code 2\n",
    "    encoding[int(mapping[tags])]=1\n",
    "            #Verification que le vecteur est bon\n",
    "    return encoding\n",
    "\n",
    "file_mapping =create_file_mapping(mapping_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion de la base de donnée <a class=\"anchor\" id=\"section_1_3\"></a>\n",
    "Ici on convertir les images 'Tiff' en numpy array pour les donner en entrée au réseau de neurones.<br>\n",
    "X : liste de matrices <br>\n",
    "Y : liste de vecteurs lignes <br>\n",
    "\n",
    "**Modification du 21/05/2021** <br>\n",
    "Parcourir les 185 sous-répertoires de \"Dataset_50x50\" et store trainX, testX, trainY, testY pour ne pas refaire la conversion images/numpy array ultèrieurement <br>\n",
    "\n",
    "**A noter** <br>\n",
    "Dans un soucis de clarté je note testX_\"nom du modèle\". Par exemple pour Alexnet les variables seront testX_Alexnet..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A décommenter pour génerer la base de donnée en matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-08-09 21:37:07.360192'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rasterArrays, targets = list(),list()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    for i in range(2,lignes):\n",
    "        if i%2==0:\n",
    "            filename = getElem(datafile_path, i, 0)\n",
    "            rasterArray = gdal_array.LoadFile(str(filename))\n",
    "                #rasterArray = gdal_array.LoadFile(file)\n",
    "                #Transpose pour mettre la profondeur à la fin \n",
    "            rasterArray = rasterArray.transpose(1, 2, 0)\n",
    "            rasterArrays.append(rasterArray)\n",
    "                    #Gestion des labels \n",
    "            #tags=file_mapping[filename]\n",
    "            #print(tags)\n",
    "            tags = file_mapping[str(filename)]\n",
    "            \n",
    "            target = one_hot_encode(filename,file_mapping)\n",
    "            targets.append(target)\n",
    "        \n",
    "    X = asarray(rasterArrays, dtype='uint8')\n",
    "    y = asarray(targets, dtype='uint8')\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y, test_size=SPLIT, shuffle=True)\n",
    "\n",
    "#print(targets)\n",
    "print('Il y a ',X.shape[0],' matrices, de tailles ',X.shape[1], 'x', X.shape[2], 'avec' ,X.shape[3], 'bandes')\n",
    "print('La liste de sortie est composée de' ,y.shape[0] ,' vecteurs de ',y.shape[1], 'colonnes chacun ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pour afficher une matrice sans la limite habituelle de Jupyter Lab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=numpy.inf)\n",
    "print(testY_alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Lignes magiques : %store pour enregistrer et %store -r pour récuperer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trainX\n",
    "%store -r trainY\n",
    "%store -r testX\n",
    "%store -r testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Callback pour avoir la matrice de confusion chaque 100 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class ConfusionMatrixCallback(Callback):\n",
    "    def __init__(self, experiment, inputs, targets):\n",
    "        self.experiment = experiment\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #if epoch%100==0: \n",
    "        predicted = self.model.predict(self.inputs)\n",
    "        self.experiment.log_confusion_matrix(\n",
    "            self.targets,\n",
    "            predicted,\n",
    "            title=\"Confusion Matrix, Epoch #%d\" % (epoch + 1),\n",
    "            file_name=\"confusion-matrix-%03d.json\" % (epoch + 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Callback pour avoir la matrice de confusion chaque 100 epochs avec des images comme exemple"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class ConfusionMatrixCallbackReuseImages(Callback):\n",
    "    def __init__(self, experiment, inputs, targets, confusion_matrix):\n",
    "        self.experiment = experiment\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch%100==0: \n",
    "            predicted = self.model.predict(self.inputs)\n",
    "            self.confusion_matrix.compute_matrix(self.targets, predicted, images=self.inputs)\n",
    "            self.experiment.log_confusion_matrix(\n",
    "                matrix=self.confusion_matrix,\n",
    "                title=\"Confusion Matrix, Epoch #%d\" % (epoch + 1),\n",
    "                file_name=\"confusion-matrix-%03d.json\" % (epoch + 1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_weights= self.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model = SaveBestModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation du CNN <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Exemple avec hyperparamètres : le modèle prend comme paramètre l'expérience et chque hyperparamètre est définir comme : \"experiment.get_parameter(\"nom_du_parametre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunits=519\n",
    "def m3_fusion(experiment):\n",
    "    in_shape = Input(shape=(25, 25, 4))\n",
    "    out_shape=11  \n",
    "    \n",
    "    conv_1 = Conv2D(experiment.get_parameter(\"nunits\")/2, (7, 7), padding='valid', activation='relu')(in_shape)\n",
    "    conv_1 = BatchNormalization()(conv_1)  \n",
    "    \n",
    "    pool_1 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_1)\n",
    "    \n",
    "    conv_2 = Conv2D(experiment.get_parameter(\"nunits\"), (3, 3), padding='valid', activation='relu')(pool_1)\n",
    "    conv_2 = BatchNormalization()(conv_2)  \n",
    "    \n",
    "    conv_3 = Conv2D(experiment.get_parameter(\"nunits\"), (3, 3), padding='same', activation='relu')(conv_2)\n",
    "    conv_3 = BatchNormalization()(conv_3)  \n",
    "    conv_3 = keras.layers.concatenate([conv_2, conv_3])\n",
    "    \n",
    "    conv_4 = Conv2D(experiment.get_parameter(\"nunits\"), (1, 1), padding='valid', activation='relu')(conv_3)\n",
    "    conv_4 = BatchNormalization()(conv_4)  \n",
    "\n",
    "    flatten= GlobalAveragePooling2D()(conv_4)\n",
    "    \n",
    "    dropout = Dropout (experiment.get_parameter(\"dropout\"))(flatten)\n",
    "    output = Dense(out_shape, activation ='softmax')(dropout)\n",
    "    \n",
    "    model = Model(inputs=in_shape, outputs=output)\n",
    "\n",
    "    #print(model.summary())\n",
    "    #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "# define model\n",
    "#model = m3_fusion()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nunits=519\n",
    "with mirrored_strategy.scope(): #Lorsqu'il y'a plusieurs GPU\n",
    "    def m3_fusion():\n",
    "        in_shape =Input(shape=(50, 50, 4))\n",
    "        out_shape=10\n",
    "\n",
    "        conv_1 = Conv2D(nunits/2, (7, 7), padding='valid', activation='relu')(in_shape)\n",
    "        conv_1 = BatchNormalization()(conv_1)  \n",
    "\n",
    "        pool_1 = MaxPooling2D((2, 2), strides=(2, 2), padding='same')(conv_1)\n",
    "\n",
    "        conv_2 = Conv2D(nunits, (3, 3), padding='valid', activation='relu')(pool_1)\n",
    "        conv_2 = BatchNormalization()(conv_2)  \n",
    "\n",
    "        conv_3 = Conv2D(nunits, (3, 3), padding='same', activation='relu')(conv_2)\n",
    "        conv_3 = BatchNormalization()(conv_3)  \n",
    "        conv_3 = keras.layers.concatenate([conv_2, conv_3])\n",
    "\n",
    "        conv_4 = Conv2D(nunits, (1, 1), padding='valid', activation='relu')(conv_3)\n",
    "        conv_4 = BatchNormalization()(conv_4)  \n",
    "\n",
    "        flatten= GlobalAveragePooling2D()(conv_4)\n",
    "\n",
    "        dropout = Dropout (0.3)(flatten)\n",
    "        output = Dense(out_shape, activation ='softmax')(dropout)\n",
    "\n",
    "        model = Model(inputs=in_shape, outputs=output)\n",
    "\n",
    "        #print(model.summary())\n",
    "        #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    # define model\n",
    "    #model = m3_fusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Alexnet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.optimizers import SGD\n",
    "#AlexNet pour les Tests \n",
    "def define_model(experiment):\n",
    "    in_shape=(227,227, 4)\n",
    "    out_shape=30\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=in_shape),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(experiment.get_parameter(\"HIDDEN_DIM\"), activation='relu'),\n",
    "        keras.layers.Dropout(experiment.get_parameter(\"DROPOUT\")),\n",
    "        keras.layers.Dense(experiment.get_parameter(\"HIDDEN_DIM\"), activation='relu'),\n",
    "        keras.layers.Dropout(experiment.get_parameter(\"DROPOUT\")),\n",
    "        keras.layers.Dense(out_shape, activation='softmax')\n",
    "        ])\n",
    "\n",
    "            # compile model\n",
    "    opt = SGD(lr=LEARNING_RATE, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "# define model\n",
    "#model = define_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Experimentation : Nouveau modèle\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def define_model():\n",
    "    in_shape=(50, 50, 4)\n",
    "    out_shape=30\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=10, kernel_size=(7,7), activation='relu', input_shape=in_shape),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=10, kernel_size=(5,5), activation='relu', padding=\"same\"),  \n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(out_shape, activation='softmax')\n",
    "    ])\n",
    "\n",
    "        # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "# define model\n",
    "model = define_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predicted_labels = model.predict(testX)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix = experiment.create_confusion_matrix()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix.compute_matrix(testX_alexnet, predicted_labels, images=testX_alexnet, image_shape=(227,227))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training <a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = ConfusionMatrixCallback(experiment, testX, testY)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "checkpoint_filepath='checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-08-09 21:37:14.698740'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(experiment, model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(\n",
    "        trainX,\n",
    "        trainY,\n",
    "        batch_size=32,\n",
    "        epochs=100,\n",
    "        callbacks=[callback, save_best_model],\n",
    "        validation_data=(testX, testY),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(experiment, model, x_test, y_test):\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy', min_delta = 0.03, mode ='max', patience=40, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Callbacks: Matrice de confusion + early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Décommenter la boucle \"for experiment in opt.get_experiments(project_name=\"Remote_sensing_classif\")\"si recherche d'hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   5/5611 [..............................] - ETA: 4:01 - loss: 2.6515 - accuracy: 0.2182 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0191s vs `on_train_batch_end` time: 0.0202s). Check your callbacks.\n",
      "5611/5611 [==============================] - 296s 52ms/step - loss: 0.8069 - accuracy: 0.7302 - val_loss: 0.5731 - val_accuracy: 0.8094\n",
      "Epoch 2/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.4869 - accuracy: 0.8322 - val_loss: 0.7414 - val_accuracy: 0.7832\n",
      "Epoch 3/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.3876 - accuracy: 0.8649 - val_loss: 0.9648 - val_accuracy: 0.7048\n",
      "Epoch 4/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.3363 - accuracy: 0.8828 - val_loss: 2.5237 - val_accuracy: 0.6445\n",
      "Epoch 5/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.3025 - accuracy: 0.8959 - val_loss: 0.4107 - val_accuracy: 0.8562\n",
      "Epoch 6/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.2727 - accuracy: 0.9059 - val_loss: 0.4046 - val_accuracy: 0.8831\n",
      "Epoch 7/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.2535 - accuracy: 0.9123 - val_loss: 0.9404 - val_accuracy: 0.7288\n",
      "Epoch 8/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.2396 - accuracy: 0.9161 - val_loss: 1.4470 - val_accuracy: 0.7251\n",
      "Epoch 9/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.2227 - accuracy: 0.9225 - val_loss: 1.1819 - val_accuracy: 0.7893\n",
      "Epoch 10/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.2103 - accuracy: 0.9266 - val_loss: 0.3093 - val_accuracy: 0.9024\n",
      "Epoch 11/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.2034 - accuracy: 0.9302 - val_loss: 0.8268 - val_accuracy: 0.8306\n",
      "Epoch 12/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1899 - accuracy: 0.9345 - val_loss: 0.7604 - val_accuracy: 0.8051\n",
      "Epoch 13/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1828 - accuracy: 0.9360 - val_loss: 4.0594 - val_accuracy: 0.5528\n",
      "Epoch 14/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1752 - accuracy: 0.9382 - val_loss: 7.2381 - val_accuracy: 0.8803\n",
      "Epoch 15/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1653 - accuracy: 0.9421 - val_loss: 0.7977 - val_accuracy: 0.8573\n",
      "Epoch 16/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1542 - accuracy: 0.9463 - val_loss: 3.5042 - val_accuracy: 0.8988\n",
      "Epoch 17/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1478 - accuracy: 0.9489 - val_loss: 1.4636 - val_accuracy: 0.7117\n",
      "Epoch 18/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1418 - accuracy: 0.9502 - val_loss: 0.5188 - val_accuracy: 0.8957\n",
      "Epoch 19/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.1351 - accuracy: 0.9518 - val_loss: 1.9950 - val_accuracy: 0.8051\n",
      "Epoch 20/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.1283 - accuracy: 0.9547 - val_loss: 1.2868 - val_accuracy: 0.8216\n",
      "Epoch 21/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.1216 - accuracy: 0.9569 - val_loss: 5.0223 - val_accuracy: 0.5540\n",
      "Epoch 22/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.1186 - accuracy: 0.9589 - val_loss: 1.0074 - val_accuracy: 0.9202\n",
      "Epoch 23/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.1095 - accuracy: 0.9621 - val_loss: 3.0244 - val_accuracy: 0.7823\n",
      "Epoch 24/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.1042 - accuracy: 0.9640 - val_loss: 1.6333 - val_accuracy: 0.8148\n",
      "Epoch 25/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0970 - accuracy: 0.9663 - val_loss: 1.6471 - val_accuracy: 0.8415\n",
      "Epoch 26/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0924 - accuracy: 0.9678 - val_loss: 0.6282 - val_accuracy: 0.8581\n",
      "Epoch 27/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0884 - accuracy: 0.9699 - val_loss: 0.4270 - val_accuracy: 0.9260\n",
      "Epoch 28/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0837 - accuracy: 0.9715 - val_loss: 1.5149 - val_accuracy: 0.8893\n",
      "Epoch 29/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0790 - accuracy: 0.9721 - val_loss: 1.8362 - val_accuracy: 0.8307\n",
      "Epoch 30/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0772 - accuracy: 0.9734 - val_loss: 4.1431 - val_accuracy: 0.7624\n",
      "Epoch 31/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0748 - accuracy: 0.9740 - val_loss: 2.2854 - val_accuracy: 0.6918\n",
      "Epoch 32/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0706 - accuracy: 0.9754 - val_loss: 2.7280 - val_accuracy: 0.8954\n",
      "Epoch 33/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0654 - accuracy: 0.9774 - val_loss: 2.4783 - val_accuracy: 0.8197\n",
      "Epoch 34/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0646 - accuracy: 0.9780 - val_loss: 3.7033 - val_accuracy: 0.9052\n",
      "Epoch 35/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0632 - accuracy: 0.9784 - val_loss: 2.1393 - val_accuracy: 0.8852\n",
      "Epoch 36/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0603 - accuracy: 0.9795 - val_loss: 1.8046 - val_accuracy: 0.8051\n",
      "Epoch 37/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0619 - accuracy: 0.9789 - val_loss: 1.4116 - val_accuracy: 0.8555\n",
      "Epoch 38/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0552 - accuracy: 0.9814 - val_loss: 1.3285 - val_accuracy: 0.7999\n",
      "Epoch 39/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0528 - accuracy: 0.9824 - val_loss: 1.6422 - val_accuracy: 0.8851\n",
      "Epoch 40/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0514 - accuracy: 0.9826 - val_loss: 2.0646 - val_accuracy: 0.9134\n",
      "Epoch 41/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0520 - accuracy: 0.9828 - val_loss: 1.4632 - val_accuracy: 0.9371\n",
      "Epoch 42/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 2.2859 - val_accuracy: 0.9336\n",
      "Epoch 43/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0482 - accuracy: 0.9839 - val_loss: 0.7293 - val_accuracy: 0.9293\n",
      "Epoch 44/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0458 - accuracy: 0.9846 - val_loss: 3.0670 - val_accuracy: 0.8406\n",
      "Epoch 45/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0454 - accuracy: 0.9850 - val_loss: 3.4567 - val_accuracy: 0.9283\n",
      "Epoch 46/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 1.0662 - val_accuracy: 0.9063\n",
      "Epoch 47/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0440 - accuracy: 0.9856 - val_loss: 0.7331 - val_accuracy: 0.9322\n",
      "Epoch 48/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 2.6507 - val_accuracy: 0.9317\n",
      "Epoch 49/100\n",
      "5611/5611 [==============================] - 297s 53ms/step - loss: 0.0401 - accuracy: 0.9868 - val_loss: 1.4722 - val_accuracy: 0.8903\n",
      "Epoch 50/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0421 - accuracy: 0.9862 - val_loss: 1.5522 - val_accuracy: 0.9270\n",
      "Epoch 51/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0391 - accuracy: 0.9871 - val_loss: 0.9352 - val_accuracy: 0.9294\n",
      "Epoch 52/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.9219 - val_accuracy: 0.9013\n",
      "Epoch 53/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0373 - accuracy: 0.9876 - val_loss: 3.0750 - val_accuracy: 0.8879\n",
      "Epoch 54/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0374 - accuracy: 0.9875 - val_loss: 1.0156 - val_accuracy: 0.9214\n",
      "Epoch 55/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0364 - accuracy: 0.9881 - val_loss: 0.9454 - val_accuracy: 0.9262\n",
      "Epoch 56/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 3.1825 - val_accuracy: 0.9245\n",
      "Epoch 57/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 3.2747 - val_accuracy: 0.9138\n",
      "Epoch 58/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 9.5642 - val_accuracy: 0.9328\n",
      "Epoch 59/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.4967 - val_accuracy: 0.9246\n",
      "Epoch 60/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 2.6906 - val_accuracy: 0.9031\n",
      "Epoch 61/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.4692 - val_accuracy: 0.9231\n",
      "Epoch 62/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 3.0770 - val_accuracy: 0.9327\n",
      "Epoch 63/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 2.4984 - val_accuracy: 0.9203\n",
      "Epoch 64/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.9970 - val_accuracy: 0.8915\n",
      "Epoch 65/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 0.4513 - val_accuracy: 0.9202\n",
      "Epoch 66/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.4492 - val_accuracy: 0.9294\n",
      "Epoch 67/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0275 - accuracy: 0.9911 - val_loss: 2.7728 - val_accuracy: 0.8112\n",
      "Epoch 68/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.6055 - val_accuracy: 0.9240\n",
      "Epoch 69/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 4.0587 - val_accuracy: 0.9155\n",
      "Epoch 70/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0274 - accuracy: 0.9912 - val_loss: 1.9511 - val_accuracy: 0.9271\n",
      "Epoch 71/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 6.6159 - val_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 1.7648 - val_accuracy: 0.9069\n",
      "Epoch 73/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 2.7481 - val_accuracy: 0.9316\n",
      "Epoch 74/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 4.4457 - val_accuracy: 0.8998\n",
      "Epoch 75/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 6.8207 - val_accuracy: 0.9313\n",
      "Epoch 76/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 4.1823 - val_accuracy: 0.8211\n",
      "Epoch 77/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.9582 - val_accuracy: 0.9199\n",
      "Epoch 78/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.9666 - val_accuracy: 0.9336\n",
      "Epoch 79/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.5109 - val_accuracy: 0.9295\n",
      "Epoch 80/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.7030 - val_accuracy: 0.9339\n",
      "Epoch 81/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.6322 - val_accuracy: 0.9264\n",
      "Epoch 82/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 3.6030 - val_accuracy: 0.9118\n",
      "Epoch 83/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 1.2152 - val_accuracy: 0.9408\n",
      "Epoch 84/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 1.1004 - val_accuracy: 0.9022\n",
      "Epoch 85/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.6069 - val_accuracy: 0.9235\n",
      "Epoch 86/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 1.2547 - val_accuracy: 0.9288\n",
      "Epoch 87/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.8675 - val_accuracy: 0.9329\n",
      "Epoch 88/100\n",
      "5611/5611 [==============================] - 296s 53ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.8990 - val_accuracy: 0.9313\n",
      "Epoch 89/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 2.8135 - val_accuracy: 0.9317\n",
      "Epoch 90/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 9.4674 - val_accuracy: 0.9164\n",
      "Epoch 91/100\n",
      "5611/5611 [==============================] - 292s 52ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 2.9164 - val_accuracy: 0.9381\n",
      "Epoch 92/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 4.8814 - val_accuracy: 0.9207\n",
      "Epoch 93/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 8.5452 - val_accuracy: 0.9194\n",
      "Epoch 94/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 4.3258 - val_accuracy: 0.9131\n",
      "Epoch 95/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 4.8840 - val_accuracy: 0.9366\n",
      "Epoch 96/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 3.3985 - val_accuracy: 0.9240\n",
      "Epoch 97/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 7.0003 - val_accuracy: 0.9290\n",
      "Epoch 98/100\n",
      "5611/5611 [==============================] - 295s 53ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 11.8219 - val_accuracy: 0.9017\n",
      "Epoch 99/100\n",
      "5611/5611 [==============================] - 294s 52ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 10.2793 - val_accuracy: 0.9264\n",
      "Epoch 100/100\n",
      "5611/5611 [==============================] - 293s 52ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 2.2404 - val_accuracy: 0.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Cannot safely convert array([0.90034825, 0.94079127, 0.72429332, 0.86542516, 0.91495601,\n",
      "       0.88317142, 0.97793737, 0.97542019, 0.9905738 , 0.95369458]) object to a scalar value, using its string representation for logging.\n",
      "COMET WARNING: Cannot safely convert array([0.92411328, 0.91556028, 0.72697368, 0.90618102, 0.92180972,\n",
      "       0.87621805, 0.97743115, 0.97381183, 0.99113812, 0.9673551 ]) object to a scalar value, using its string representation for logging.\n",
      "COMET WARNING: Cannot safely convert array([0.87777488, 0.9674523 , 0.72163265, 0.82817754, 0.90820347,\n",
      "       0.89023603, 0.97844411, 0.97703387, 0.99001012, 0.94041451]) object to a scalar value, using its string representation for logging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.240379810333252, 0.9310945272445679]\n"
     ]
    }
   ],
   "source": [
    "for experiment in opt.get_experiments(project_name=\"DeepLearning_MOS\"):\n",
    "    # Log parameters, or others:\n",
    "    #experiment.log_parameter(\"epochs\", 300)\n",
    "\n",
    "        # Build the model:\n",
    "    model = m3_fusion(experiment)\n",
    "\n",
    "\n",
    "\n",
    "            # Train it:\n",
    "    train(experiment, model, trainX, trainY, testX, testY)\n",
    "\n",
    "\n",
    "    y_pred = np.argmax(testY, axis=1)\n",
    "    test = model.predict(testX)\n",
    "    rounded = np.argmax(test, axis=1)\n",
    "    f1 = f1_score(y_pred, rounded, average=None)\n",
    "\n",
    "\n",
    "    precision = precision_score(y_pred, rounded, average=None)\n",
    "    recall = recall_score(y_pred, rounded, average=None)\n",
    "\n",
    "    metrics = {\"f1\": f1,\n",
    "                    \"recall\": recall,\n",
    "                    \"precision\": precision\n",
    "                }\n",
    "\n",
    "\n",
    "    experiment.log_metrics(metrics)\n",
    "\n",
    "            # How well did it do?\n",
    "    evaluate(experiment, model, testX, testY)\n",
    "\n",
    "        # Optionally, end the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-08-10 06:40:05.820800'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Enregistrer le modèle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# serialize model to JSON\n",
    "model.set_weights(save_best_model.best_weights)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"m3_niveau2_best.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"m3_niveau2_best.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement early stopping to avoid over-fitting\n",
    "#es = EarlyStes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)opping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/benlamlih/remote-sensing-classif/f1505feb0efa415a8c89205c8be4d4c0\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [100]                  : (0.776751697063446, 0.9937451481819153)\n",
      "COMET INFO:     batch_accuracy [56200]          : (0.0625, 1.0)\n",
      "COMET INFO:     batch_loss [56200]              : (0.00016871656407602131, 2.4661829471588135)\n",
      "COMET INFO:     epoch_duration [100]            : (322.8439999999973, 327.8590000000004)\n",
      "COMET INFO:     f1                              : [0.90034825 0.94079127 0.72429332 0.86542516 0.91495601 0.88317142\n",
      " 0.97793737 0.97542019 0.9905738  0.95369458]\n",
      "COMET INFO:     loss [100]                      : (0.019582241773605347, 0.6607242822647095)\n",
      "COMET INFO:     precision                       : [0.92411328 0.91556028 0.72697368 0.90618102 0.92180972 0.87621805\n",
      " 0.97743115 0.97381183 0.99113812 0.9673551 ]\n",
      "COMET INFO:     recall                          : [0.87777488 0.9674523  0.72163265 0.82817754 0.90820347 0.89023603\n",
      " 0.97844411 0.97703387 0.99001012 0.94041451]\n",
      "COMET INFO:     val_accuracy [100]              : (0.5527513027191162, 0.9408026337623596)\n",
      "COMET INFO:     val_loss [100]                  : (0.3092513680458069, 11.821863174438477)\n",
      "COMET INFO:     validate_batch_accuracy [24100] : (0.5198863744735718, 0.96875)\n",
      "COMET INFO:     validate_batch_loss [24100]     : (0.10057300329208374, 46.9580192565918)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     trainable_params : 4237804\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad       : 1\n",
      "COMET INFO:     Adam_beta_1        : 0.9\n",
      "COMET INFO:     Adam_beta_2        : 0.999\n",
      "COMET INFO:     Adam_decay         : 1\n",
      "COMET INFO:     Adam_epsilon       : 1e-07\n",
      "COMET INFO:     Adam_learning_rate : 0.001\n",
      "COMET INFO:     Adam_name          : Adam\n",
      "COMET INFO:     Optimizer          : Adam\n",
      "COMET INFO:     epochs             : 100\n",
      "COMET INFO:     steps              : 5611\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     confusion-matrix    : 100\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
